# --------------------------------------------------------------------------
# Jesus Tordesillas Torres, Robotic Systems Lab, ETH ZÃ¼rich 
# See LICENSE file for the license information
# -------------------------------------------------------------------------- 
import cdd
import numpy as np
import torch
from colorama import Fore, Back, Style
import torch.nn as nn

def printInBoldBlue(data_string):
	print(Style.BRIGHT+Fore.BLUE+data_string+Style.RESET_ALL)
def printInBoldRed(data_string):
	print(Style.BRIGHT+Fore.RED+data_string+Style.RESET_ALL)
def printInBoldGreen(data_string):
	print(Style.BRIGHT+Fore.GREEN+data_string+Style.RESET_ALL)
def printInBoldWhite(data_string):
	print(Style.BRIGHT+Fore.WHITE+data_string+Style.RESET_ALL)


def verify(condition, message="Condition not satisfied"):
	if(condition==False):
		raise RuntimeError(message)

def getAllPqrFromQcs(qcs):
		all_P=[]
		all_q=[]
		all_r=[]
		for qc in qcs:
			all_P.append(qc.P)
			all_q.append(qc.q)
			all_r.append(qc.r)	
		return all_P, all_q, all_r

def getAllMscdFromSocs(socs):
		all_M=[]
		all_s=[]
		all_c=[]
		all_d=[]
		for soc in socs:
			all_M.append(soc.M)
			all_s.append(soc.s)
			all_c.append(soc.c)
			all_d.append(soc.d)

		return all_M, all_s, all_c, all_d


class CudaTimer():
	def __init__(self):
			pass
	def start(self):
			#See https://discuss.pytorch.org/t/how-to-measure-time-in-pytorch/26964
			self.start_event = torch.cuda.Event(enable_timing=True)
			self.end_event = torch.cuda.Event(enable_timing=True)
			self.start_event.record()

	def endAndGetTimeSeconds(self):
			self.end_event.record()
			torch.cuda.synchronize()
			return  (1e-3)*self.start_event.elapsed_time(self.end_event) #Note that elapsed_time returns the time in milliseconds


########################################################
########################################################

# Inspired by https://github.com/rfeinman/Torch-ARPACK/blob/master/arpack/power_iteration.py
# See also https://ergodic.ugr.es/cphys/LECCIONES/FORTRAN/power_method.pdf
# Note that powerIteration find the eigenvalue with largest absolute value (i.e., the dominant eigenvalue)
# v is the initial guess of the eigenvector associated with the dominant eigenvalue
# A should have shape [size_batch, n, n]
# v should have shape [n, 1]
# Everything in Pytorch
def powerIteration(A, v, tol=1e-5, max_iter=100000, eps=1e-12, check_freq=2):
		n_iter = 0
		v = torch.nn.functional.normalize(v)
		while n_iter < max_iter:
				n_iter += 1
				u = torch.nn.functional.normalize(A@v, dim=1)

				if n_iter>1 and ((n_iter % check_freq) == 0):
						distance=torch.mean(torch.abs(1 - torch.abs(  torch.transpose(v,1,2)@u ))) #Note: one disadvantage of this is that it will keep iterating until ALL the elements of the batch have converged
						if distance<tol:
								v = u
								break
				v = u
		else:
				print(f"distance={distance}")
				print('Power iteration did not converge')

		lamb =  torch.transpose(v,1,2)@A@v #torch.dot(v, torch.mv(A, v))

		return lamb

#See https://math.stackexchange.com/a/835568 (note that there are some signs wrong in that answer, but otherwise is good)
# v is the initial guess for the power iteration
# A should have shape [size_batch, n, n]
# v should have shape [n, 1]
# Everything in Pytorch
def findLargestEigenvalueUsingPowerIteration(A, v):
		lamb = powerIteration(A, v)
		condition=(lamb.flatten()<0)
		if (torch.all(condition == False)):
				return lamb
		lamb[condition,:,:]+=powerIteration(A[condition,:,:]-lamb[condition,:,:]*torch.eye(A.shape[1]), v)
		return lamb


# Other links: 
# --> https://github.com/pytorch/pytorch/blob/main/torch/nn/utils/spectral_norm.py#L80


def isZero(A):
	return (not np.any(A))

def checkMatrixisNotZero(A):
	verify(not isZero(A))

def checkMatrixisSymmetric(A):
	verify(A.shape[0]==A.shape[1])
	verify(np.allclose(A, A.T))

def checkMatrixisPsd(A, tol=0.0):
	checkMatrixisSymmetric(A)
	eigenvalues=np.linalg.eigvals(A);
	verify(np.all(eigenvalues >= -tol), f"Matrix is not PSD, min eigenvalue is {np.amin(eigenvalues)}")

def checkMatrixisPd(A):
	checkMatrixisSymmetric(A)
	eigenvalues=np.linalg.eigvals(A);
	verify(np.all(eigenvalues > 0.0), f"Matrix is not PD, min eigenvalue is {np.amin(eigenvalues)}")

def isMatrixSingular(A):
	return (np.linalg.matrix_rank(A) < self.E.shape[0])

#Taken from https://gist.github.com/sgsfak/77a1c08ac8a9b0af77393b24e44c9547
#Compute the Reduced Row Echelon Form (RREF) in Python
def rref(B, tol=1e-8):
	A = B.copy()
	rows, cols = A.shape
	r = 0
	pivots_pos = []
	row_exchanges = np.arange(rows)
	for c in range(cols):

		## Find the pivot row:
		pivot = np.argmax (np.abs (A[r:rows,c])) + r
		m = np.abs(A[pivot, c])
		if m <= tol:
			## Skip column c, making sure the approximately zero terms are
			## actually zero.
			A[r:rows, c] = np.zeros(rows-r)
		else:
			## keep track of bound variables
			pivots_pos.append((r,c))

			if pivot != r:
				## Swap current row and pivot row
				A[[pivot, r], c:cols] = A[[r, pivot], c:cols]
				row_exchanges[[pivot,r]] = row_exchanges[[r,pivot]]

			## Normalize pivot row
			A[r, c:cols] = A[r, c:cols] / A[r, c];

			## Eliminate the current column
			v = A[r, c:cols]
			## Above (before row r):
			if r > 0:
				ridx_above = np.arange(r)
				A[ridx_above, c:cols] = A[ridx_above, c:cols] - np.outer(v, A[ridx_above, c]).T
			## Below (after row r):
			if r < rows-1:
				ridx_below = np.arange(r+1,rows)
				A[ridx_below, c:cols] = A[ridx_below, c:cols] - np.outer(v, A[ridx_below, c]).T
			r += 1
		## Check if done
		if r == rows:
			break;
	return (A, pivots_pos, row_exchanges)

# Input is the matrices (A,b) that define the system Ax=b
# Ouput is the matrices (A',b') such that A'x=b' has the same solutions as Ax=b, and (A',b') have the smallest possible number of rows
# See https://mathoverflow.net/a/48867  and the row echelon form in https://en.wikipedia.org/wiki/Gaussian_elimination#General_algorithm_to_compute_ranks_and_bases
def removeRedundantEquationsFromEqualitySystem(A, b):

	A_b=np.concatenate((A, b), axis=1)

	A_b_new, pivots_pos, row_exchanges = rref(A_b)

	##### Now remove the rows that are zero
	rows_that_are_zero=[]
	for i in range(A_b_new.shape[0]):
		if(np.linalg.norm(A_b_new[i,:])<1e-7):
			rows_that_are_zero.append(i)

	A_b_new = np.delete(A_b_new, rows_that_are_zero, axis=0)
	#####################################

	##### Now get A_new and b_new from A_b_new
	A_new=A_b_new[:,:-1].reshape((-1, A.shape[1]))
	b_new=A_b_new[:,-1].reshape((-1, 1))
	#####################################

	if(A_b_new.shape[0]>0):
		assert np.linalg.matrix_rank(A_b_new)==A_b_new.shape[0]

	return A_new, b_new



#Everything in numpy
#Ellipsoid is defined as {x | (x-c)'E(x-c)<=1}
#Where E is a positive semidefinite matrix
class Ellipsoid():
	def __init__(self, E, c):

		checkMatrixisPsd(E);
		self.E=E;
		self.c=c;

	def convertToQuadraticConstraint(self):
		P=2*self.E;
		q=(-2*self.E@self.c)
		r=self.c.T@self.E@self.c-1
		return convexQuadraticConstraint(P,q,r)

#Pytorch
def quadExpression(y, P, q, r):

	P = P.to(y.device)
	q = q.to(y.device)
	r = r.to(y.device)

	if (q.ndim==2):
		qT=q.T
	else: #q is a batch
		assert q.ndim==3 
		qT=torch.transpose(q,1,2)

	result=0.5*torch.transpose(y,1,2)@P@y + qT@y + r;
	assert result.shape==(y.shape[0],1,1)
	return result

#https://stackoverflow.com/a/3844832
def all_equal(iterator):
	iterator = iter(iterator)
	try:
		first = next(iterator)
	except StopIteration:
		return True
	return all(first == x for x in iterator)

def loadpickle(name_file):
	import pickle
	with open(name_file, "rb") as input_file:
		result = pickle.load(input_file)
	return result	

def savepickle(variable, name_file):
	import pickle
	with open(name_file, 'wb') as output_file:
		pickle.dump(variable, output_file, pickle.HIGHEST_PROTOCOL)	

#https://stackoverflow.com/questions/65154622/sample-uniformly-at-random-from-a-simplex-in-python
def runif_in_simplex(n):
	''' Return uniformly random vector in the n-simplex '''

	k = np.random.exponential(scale=1.0, size=n)
	return k / sum(k)

#This function is taken from https://github.com/tfrerix/constrained-nets
def H_to_V(A, b):
	"""
	Converts a polyhedron in H-representation to
	one in V-representation using pycddlib.
	"""
	# define cdd problem and convert representation
	if len(b.shape) == 1:
		b = np.expand_dims(b, axis=1)
	mat_np = np.concatenate([b, -A], axis=1)
	if mat_np.dtype in [np.int32, np.int64]:
		nt = 'fraction'
	else:
		nt = 'float'
	mat_list = mat_np.tolist()

	mat_cdd = cdd.Matrix(mat_list, number_type=nt)
	mat_cdd.rep_type = cdd.RepType.INEQUALITY
	poly = cdd.Polyhedron(mat_cdd)
	gen = poly.get_generators()

	# convert the cddlib output data structure to numpy
	V_list = []
	R_list = []
	lin_set = gen.lin_set
	V_lin_idx = []
	R_lin_idx = []
	for i in range(gen.row_size):
		g = gen[i]
		g_type = g[0]
		g_vec = g[1:]
		if i in lin_set:
			is_linear = True
		else:
			is_linear = False
		if g_type == 1:
			V_list.append(g_vec)
			if is_linear:
				V_lin_idx.append(len(V_list) - 1)
		elif g_type == 0:
			R_list.append(g_vec)
			if is_linear:
				R_lin_idx.append(len(R_list) - 1)
		else:
			raise ValueError('Generator data structure is not valid.')

	V = np.asarray(V_list)
	R = np.asarray(R_list)

	# by convention of cddlib, those rays associated with R_lin_idx
	# are not constrained to non-negative coefficients
	if len(R) > 0:
		R = np.concatenate([R, -R[R_lin_idx, :]], axis=0)

	V=V.T; 
	R=R.T;

	if(R.size==0):
		R=np.array([[]])#Simply add a dimension, so that both V and R are 2D matrices

	if(V.size==0):
		V=np.array([[]])#Simply add a dimension, so that both V and R are 2D matrices

	#Each column of V is a vertex
	#Each column of R is a ray

	return V, R




